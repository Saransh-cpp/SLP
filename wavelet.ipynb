{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8733d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import splitfolders\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Flatten\n",
    "import tensorflow_wavelets.Layers.DWT as DWT\n",
    "import tensorflow_wavelets.Layers.DTCWT as DTCWT\n",
    "import tensorflow_wavelets.Layers.DMWT as DMWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dataset/train.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        category = line[-2]\n",
    "        filename = line[-3]\n",
    "        \n",
    "        try:\n",
    "            if category == \"positive\":\n",
    "                os.replace(f\"./dataset/train/{filename}\", f\"./dataset/data/positive/{filename}\")\n",
    "            elif category == \"negative\":\n",
    "                os.replace(f\"./dataset/train/{filename}\", f\"./dataset/data/negative/{filename}\")\n",
    "        except FileNotFoundError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ecc3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dataset/test.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        category = line[-2]\n",
    "        filename = line[-3]\n",
    "        \n",
    "        try:\n",
    "            if category == \"positive\":\n",
    "                os.replace(f\"./dataset/test/{filename}\", f\"./dataset/data/positive/{filename}\")\n",
    "            elif category == \"negative\":\n",
    "                os.replace(f\"./dataset/test/{filename}\", f\"./dataset/data/negative/{filename}\")\n",
    "        except FileNotFoundError as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./dataset/data\"):\n",
    "    os.renames(\"./dataset/data\", \"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b087270",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(), './data_split')):\n",
    "    splitfolders.ratio(\"./data\", output=\"./data_split\", seed=1337, ratio=(.7, .2, .1), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff66d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "vgg19.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d977cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and output layer\n",
    "flatten_layer = Flatten()\n",
    "prediction_layer = Dense(2, activation='softmax')\n",
    "\n",
    "# the final model\n",
    "model = Sequential([\n",
    "    DWT.DWT(concat=1),\n",
    "    vgg19,\n",
    "    flatten_layer,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "model.build(input_shape=((None, 224, 224, 3)))\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93602d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e685f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # rescaling pixel values\n",
    "    rescale=1./255,\n",
    "    \n",
    "    # augmenting the data\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.4,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "# for cross validation data\n",
    "val_datagen = ImageDataGenerator(\n",
    "    # rescaling pixel values\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "# obtaining training dataset\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    './data_split/train/',\n",
    "     target_size=(224, 224),\n",
    "     batch_size=32,\n",
    "     class_mode='categorical'\n",
    ")\n",
    "\n",
    "# obtaining cross-validation dataset\n",
    "validation_set = val_datagen.flow_from_directory(\n",
    "    './data_split/val/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"slp_model.tflite\", \"wb\") as m:\n",
    "    m.write(tflite_model)\n",
    "    \n",
    "model.save(\"slp_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "plt.plot(epochs, acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Cross validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Cross validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c59374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"./model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc99d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba694cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb30de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = []\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "#     print(np.argmax(y_pred[i]))\n",
    "    labels_pred.append(np.argmax(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_set.labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe4ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(labels, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
